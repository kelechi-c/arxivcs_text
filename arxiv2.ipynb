{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["! pip install PyPDF2 selenium"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import requests, shutil, os, rich, time, re\n","\n","from tqdm.auto import tqdm\n","from PyPDF2 import PdfReader\n","from selenium import webdriver\n","from selenium.webdriver.firefox.options import Options\n","from selenium.webdriver.common.by import By"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# sample_fields = ['cs.AI', 'cs.CL', 'cs.CC', 'cs.CE', 'cs.CG', 'cs.GT', 'cs.CV', 'cs.CY', 'cs.CR', 'cs.DS']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T22:05:50.658091Z","iopub.status.busy":"2024-06-19T22:05:50.657659Z","iopub.status.idle":"2024-06-19T22:05:51.063838Z","shell.execute_reply":"2024-06-19T22:05:51.062368Z","shell.execute_reply.started":"2024-06-19T22:05:50.658055Z"},"trusted":true},"outputs":[],"source":["def get_section_list():  # get list of sections\n","    # initialize driver\n","    drive_opts = Options()\n","    drive_opts.add_argument(\"-headless\")\n","    driver = webdriver.Firefox(options=drive_opts)\n","    print(\"Driver init\")\n","\n","    # load page content\n","    driver.get(\"https://arxiv.org/\")\n","\n","    links = driver.find_elements(By.CSS_SELECTOR, \"li > a\")\n","    links = links[4:]\n","\n","    print(len(links))\n","\n","    field_acronyms = [link.get_attribute(\"id\") for link in links]\n","\n","    field_acronyms = [k for k in field_acronyms if k.startswith(\"cs\")]\n","    driver.quit()\n","\n","    print(field_acronyms)\n","    print(len(field_acronyms))\n","    return field_acronyms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T22:05:51.066064Z","iopub.status.busy":"2024-06-19T22:05:51.065344Z","iopub.status.idle":"2024-06-19T22:05:51.072194Z","shell.execute_reply":"2024-06-19T22:05:51.070925Z","shell.execute_reply.started":"2024-06-19T22:05:51.06603Z"},"trusted":true},"outputs":[],"source":["def download_files(link_list: list, title_list: list, pdf_folder: str):\n","    k = 0\n","\n","    for file_link, title in tqdm(zip(link_list, title_list)):\n","        try:\n","            response = requests.get(str(file_link), stream=True)\n","            file_path = os.path.join(pdf_folder, f\"{title}_{k}.pdf\")\n","\n","            with open(file_path, \"wb\") as file:\n","                file.write(response.content)\n","                response.raw.decode_content = True\n","\n","                shutil.copyfileobj(response.raw, file)\n","                print(f\"File @ {k}\")\n","            k += 1\n","\n","        except Exception as e:\n","            print(f\"[error]{e}\")\n","            \n","            continue\n","\n","    print(f\"{k} pdfs downloaded from arxiv 🍻\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T22:05:51.075188Z","iopub.status.busy":"2024-06-19T22:05:51.074813Z","iopub.status.idle":"2024-06-19T22:06:12.845246Z","shell.execute_reply":"2024-06-19T22:06:12.844033Z","shell.execute_reply.started":"2024-06-19T22:05:51.075156Z"},"trusted":true},"outputs":[],"source":["def clean_text(text):  # regex cleaning function\n","    regex_format = (\n","        r\"[^\\w\\s\\d]\"  # Leaves behind only text, digits, and whitespace characters\n","    )\n","    cleaned_text = re.sub(regex_format, \"\", text)\n","\n","    return cleaned_text\n","\n","\n","def pdf2text_file(pdf_file: str):\n","    # extrcat text from pdf\n","    #try:\n","    extract_text = \"\"\n","    pdf_read = PdfReader(pdf_file)\n","\n","    for page_num in tqdm(range(len(pdf_read.pages))):\n","        page = pdf_read.pages[page_num]\n","        extract_text += page.extract_text()\n","        extract_text = clean_text(extract_text)\n","\n","    return extract_text"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def merge_pdfs(file_list: list, out_text_file: str):\n","    text_corpus = \"\"\n","    try:\n","        for pdf in tqdm(file_list, colour=\"blue\"):  # extract from pdf in queue\n","            try:\n","                text_extract = pdf2text_file(pdf)\n","                text_corpus += text_extract  # concat text and add space before the next one is added\n","                \n","                print(f\"Extracted [white] {pdf}\")\n","\n","                with open(out_text_file, \"w\", encoding=\"utf-8\") as file:\n","                    file.write(text_corpus)  # write to text file\n","\n","            except Exception as e:\n","                print(e)\n","\n","                continue\n","\n","        # success message\n","        print(\n","            f\"{len(file_list)} research paper PDFs extracted to single text file [bold green]{out_text_file}[/bold green] of size {shutil.disk_usage(out_text_file)}\"\n","        )\n","\n","        return text_corpus\n","\n","    # exception hanndling and colored output\n","    except Exception as e:\n","        print(f\"[bold red] Error in extraction --> {e}\")\n","\n","    return text_corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T22:06:12.848346Z","iopub.status.busy":"2024-06-19T22:06:12.847266Z","iopub.status.idle":"2024-06-19T22:06:12.855549Z","shell.execute_reply":"2024-06-19T22:06:12.854286Z","shell.execute_reply.started":"2024-06-19T22:06:12.848296Z"},"trusted":true},"outputs":[],"source":["def arxiv_scraper(section: str):\n","    arxiv_tree_url = f\"http://arxiv.org/list/{section}\"\n","\n","    # LG(machine learning), CL(computation and language)\n","    pdf_folder = f\"arxiv_{section}_pdfs\"\n","    os.mkdir(pdf_folder)\n","\n","    # initialize driver\n","    drive_opts = Options()\n","    drive_opts.add_argument(\"-headless\")\n","    driver = webdriver.Firefox(options=drive_opts)\n","    print(\"Driver init\")\n","\n","    # load page content\n","    driver.get(f\"{arxiv_tree_url}/recent?skip=0&show=2000\")\n","    print(\"Driver loaded...🔥\")\n","\n","    # get all pdf links and titles\n","    pdf_links = driver.find_elements(By.LINK_TEXT, \"pdf\")\n","    titles = driver.find_elements(By.CLASS_NAME, \"list-title\")\n","    print(f\"Number of links  => {len(pdf_links)}\")\n","    print(f\"Number of titles  => {len(titles)}\")\n","\n","    paper_titles = [tit.text for tit in titles]\n","    print(len(pdf_links), len(paper_titles))\n","\n","    pdf_links = [link.get_attribute(\"href\") for link in pdf_links]\n","    print(f\"Link and titles retrieved. e.g => {paper_titles[0]}: {pdf_links[0]}\")\n","\n","    driver.quit()\n","    print(\"driver terminated\")\n","\n","    download_files(pdf_links, paper_titles, pdf_folder)\n","\n","    print(\"Begin pdf merging\")\n","    pdf_list = os.listdir(pdf_folder)\n","    pdf_list = [os.path.join(os.getcwd(), pdf_folder, pdfile) for pdfile in pdf_list]\n","\n","    out_text_file = f\"arxiv_cspapers_{section}.txt\"\n","\n","    corpus = merge_pdfs(pdf_list, out_text_file)\n","    print(\"Extraction and merging complete ⚡️⚡️\")\n","\n","    return corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# main\n","cs_fields = get_section_list()\n","\n","\n","text_corpus = \"\"\n","\n","for cs_field in cs_fields:\n","    try:\n","        print(f\"begin for {cs_field}\")\n","        arxiv_corpus = arxiv_scraper(cs_field)\n","        text_corpus += arxiv_corpus\n","    except Exception as e:\n","        print(f\"error{e}\")\n","\n","        continue\n","\n","with open(\"arxiv_cs_researchpapers.txt\", \"w\", encoding=\"utf-8\") as file:\n","    file.write(text_corpus)\n","\n","print(f\"total length of corpus => {len(text_corpus)}\")\n","\n","print(\"Arxiv computer science research text data successfully scraped\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
